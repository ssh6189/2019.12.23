머신러닝

분류
예측하려는 대상의 속성(실명 변수)를 입력 받고, 목표변수가 갖고 있는 카테고리(범주형)값 중에서는 어느 한값으로 분류하여 예측한다.
고객분류, 질병진단, 스팸메일 필터링, 음성인식 등 목표 변수가 카테고리 값을 갖는 경우에 사용한다.

KNN, SVM, Decision Tree, Logistic Regression 등

목표변수가 카테고리로 분류되는 경우
목표변수 = 종속변수

KNN(K-Nearest Neighbors)
새로운 관측값이 주어지면, 기존 데이터 주엥서 가장 속성이 비슷한  k개의 이웃을 먼저 찾는다.
가까운 이웃들이 갖고 있는 목표값과 같은 값으로 분류하여 예측한다.
k값에 따라 예측의 정확도가 달라지므로, 적절한 값을 찾는것이 매우 중요하다.
새로운 데이터가 들어왔을때, 기존 데이터 사이의 거리를 재서 이웃들을 뽑는다.
모델 생성과정 없이 각각의 관측치만을 이용하여, 분류/회귀 등을 수행한다.
KNN의 하이퍼레이터

k값을 낮게 하면, 오버피팅 발생

KNN
유클리드 디스턴스 : 가장 흔히 사용하는 거리 척도, 두 관측치 사이의 직선 최단거리
멘하탄 디스턴스 : A에서 B로 이동할때 각 좌표축 방향으로, 이동할 경우에 계산되는 거리
멘하탄 디스턴스 : 변수, 내분산 변수, 간 공분산을 모두 반영하여 거리를 계산하는 방식
코릴레이션 디스턴스 :

KNN의 알고리즘을 통해 분류분석을 할때

정확도 : True로 예측한 분석값중에서 실제 값이 True일 경우
재현율 : 실제 값이 True인 분석대상 중에서 True로 예측하여 모형이 적중한 비율, 모양의 완전성을 나타내는 지표, 재현율이 높다는것은 예측오류가 낮다는뜻

FT자료 : 정확도와 재현율이 균등하게 반영될 수 있도록 정확도와 재현율의 조화평균을 계산한 값
모형의 예측력을 종합적으로 평가하는 지표
값이 높을수록 분류모형의 예측력이 좋다고 말할 수 있다.

KNN을 수행하기 전에 변수를 정규화 해주어야 한다.

KNN은 학습 데이터 내에 끼어있는 노이즈의 영향을 크게 받지 않으며, 학습데이터 수가 많다면 꽤 효과적인 알고리즘이다.
노이즈 : 대표적으로 NAN